# Usage
<p>This job helper is using <code>requests</a> library to scrape the HTML and also </code>selenium</a> to interact with the browser. The main reason of this code is to help job seekers to optimize the job search and get higher chance to get the job.</p>
<p>First, we get the driver and store it in a selenium chrome library and store <code>txt</code> as a sign that the driver has been downloaded, so later when we run the program again it won't download the driver because we don't want that.</p>
<p> After the webdriver download is done, we are looking for the working links for pagination with the htlm requests and then sort the links we get with regex. We store the working links to be used in txt later and check for the existence of the sorted links if we run the code again. Then, we use the links to log in and after that we scrape the requirements in <code>txt</code> so we can construct the best reasons why we apply for the job. This code involves manual filling for the reasons why we apply for the job but it automates the login and store the requirements in a text so we don't have to go backward just to see the requirements plus it will loop through the entire links so we can apply for different jobs efficiently.</p>
